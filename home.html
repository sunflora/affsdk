<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <title> by affectiva</title>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <meta name="robots" content="noindex, nofollow">
  <meta name="googlebot" content="noindex, nofollow">


  <script
    type="text/javascript"
    src="//code.jquery.com/jquery-3.1.0.slim.js"
    
  ></script>

    <link rel="stylesheet" type="text/css" href="/css/result-light.css">

      <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
      <script type="text/javascript" src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
      <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap-theme.min.css">
      <script type="text/javascript" src="https://download.affectiva.com/js/3.2/affdex.js"></script>
  <style type="text/css">
    
  </style>
  
</head>
<body>
  <body>
  <div class="container-fluid">
    <div class="row">
      <div class="col-md-10" id="affdex_elements" style="width:680px;height:480px;">
        <canvas id="image_canvas">
      </div>
      <div class="col-md-4">
        <div style="height:25em;">
          <strong>EMOTION TRACKING RESULTS</strong>
          <div id="results" style="word-wrap:break-word;"></div>
        </div>
        <div>
          <strong>DETECTOR LOG MSGS</strong>
        </div>
        <div id="logs"></div>
      </div>
    </div>
    <div>
      <input id="upload_button" type="file" accept="image/*" onchange="loadFile(event)" style="visibility: hidden;">
      <h3>Affectiva JS SDK PhotoDetector to track different emotions.</h3>
      <p>
        <strong>Instructions</strong>
        </br>
        Once the detector is initialized, the "choose file" button will be visible. Choose file to upload a file.
        <br/> When a face is detected, the probabilities of the different emotions are written to the DOM.
        <br/>
      </p>
    </div>
  </div>
</body>

    <script type="text/javascript">

    //<![CDATA[
        //Construct a PhotoDetector

/*
   Face detector configuration - If not specified, defaults to       
   affdex.FaceDetectorMode.LARGE_FACES
   affdex.FaceDetectorMode.LARGE_FACES=Faces occupying large portions of the frame
   affdex.FaceDetectorMode.SMALL_FACES=Faces occupying small portions of the frame
*/
var faceMode = affdex.FaceDetectorMode.LARGE_FACES;

var detector = new affdex.PhotoDetector();

//Enable detection of all Expressions, Emotions and Emojis classifiers.
detector.detectAllEmotions();
detector.detectAllExpressions();
detector.detectAllEmojis();
detector.detectAllAppearance();

//Add a callback to notify when the detector is initialized and ready for runing.
detector.addEventListener("onInitializeSuccess", function() {
  log('#logs', "The detector reports initialized");

  $("#upload_button").css("visibility", "visible");
});

//Add a callback to receive the results from processing an image.
//The faces object contains the list of the faces detected in an image.
//Faces object contains probabilities for all the different expressions, emotions and appearance metrics
detector.addEventListener("onImageResultsSuccess", function(faces, image, timestamp) {
  drawImage(image);
  $('#results').html("");
  log('#results', "Timestamp: " + timestamp.toFixed(2));
  log('#results', "Number of faces found: " + faces.length);
  if (faces.length > 0) {
    log('#results', "Appearance: " + JSON.stringify(faces[0].appearance));
    log('#results', "Emotions: " + JSON.stringify(faces[0].emotions, function(key, val) {
      return val.toFixed ? Number(val.toFixed(0)) : val;
    }));
    log('#results', "Expressions: " + JSON.stringify(faces[0].expressions, function(key, val) {
      return val.toFixed ? Number(val.toFixed(0)) : val;
    }));
    log('#results', "Emoji: " + faces[0].emojis.dominantEmoji);
    //drawFeaturePoints(image, faces[0].featurePoints);
    //log('#results', "feature points: " + JSON.stringify(faces[0].featurePoints));
    drawImageAndFeaturePoints(image, faces[0].featurePoints);
  }
});

//Add a callback to notify if failed receive the results from processing an image.
detector.addEventListener("onImageResultsFailure", function(image, timestamp, error) {
  log('#logs', 'Failed to process image err=' + error);
});

//Initialize the emotion detector
log("#logs", "Starting the detector .. please wait");
detector.start();


//Once the image is loaded, pass it down for processing
function imageLoaded(event) {

  var contxt = document.createElement('canvas').getContext('2d');
  contxt.canvas.width = this.width;
  contxt.canvas.height = this.height;
  contxt.drawImage(this, 0, 0, this.width, this.height);

  // Pass the image to the detector to track emotions
  if (detector && detector.isRunning) {
    detector.process(contxt.getImageData(0, 0, this.width, this.height), 0);
  }
}

//Load the selected image
function loadFile(event) {
  $('#results').html("");
  var img = new Image();
  var reader = new FileReader();
  reader.onload = function() {
    img.onload = imageLoaded;
    img.src = reader.result;
  };
  reader.readAsDataURL(event.target.files[0]);
};

//Convienence function for logging to the DOM
function log(node_name, msg) {
  $(node_name).append("<span>" + msg + "</span><br />")
}

//Draw Image to container
function drawImage(img) {
  //alert(img);

  var contxt = $('#image_canvas')[0].getContext('2d');

  var temp = document.createElement('canvas').getContext('2d');
  temp.canvas.width = img.width;
  temp.canvas.height = img.height;
  temp.putImageData(img, 0, 0);

  var image = new Image();
  image.src = temp.canvas.toDataURL("image/png");
  //image.src = temp.canvas.toDataURL("image/jpeg");

  image.onload = function() {
    //Scale the image to 640x480 - the size of the display container.
    contxt.canvas.width = img.width <= 640 ? img.width : 640;
    contxt.canvas.height = img.height <= 480 ? img.height : 480;

    var hRatio = contxt.canvas.width / img.width;
    var vRatio = contxt.canvas.height / img.height;
    var ratio = Math.min(hRatio, vRatio);

    //Draw the image on the display canvas
    contxt.clearRect(0, 0, contxt.canvas.width, contxt.canvas.height);

    contxt.scale(ratio, ratio);
    contxt.drawImage(image, 0, 0);
  }
}

//Draw the detected facial feature points on the image
function drawFeaturePoints(img, featurePoints) {

  //alert("DrawFeaturePoints");

  var contxt = $('#image_canvas')[0].getContext('2d');

  var hRatio = contxt.canvas.width / img.width;
  var vRatio = contxt.canvas.height / img.height;
  var ratio = Math.min(hRatio, vRatio);

  contxt.strokeStyle = "#FFFFFF";
  for (var id in featurePoints) {
    contxt.beginPath();
    contxt.arc(featurePoints[id].x,
      featurePoints[id].y, 2, 0, 2 * Math.PI);
    contxt.stroke();

  }
}

//Draw the detected facial feature points on the image
function drawImageAndFeaturePoints(img, featurePoints) {

  var contxt = $('#image_canvas')[0].getContext('2d');

  var temp = document.createElement('canvas').getContext('2d');
  temp.canvas.width = img.width;
  temp.canvas.height = img.height;
  temp.putImageData(img, 0, 0);

  var image = new Image();
  image.src = temp.canvas.toDataURL("image/png");
  //image.src = temp.canvas.toDataURL("image/jpeg");

  image.onload = function() {
    //Scale the image to 640x480 - the size of the display container.
    contxt.canvas.width = img.width <= 640 ? img.width : 640;
    contxt.canvas.height = img.height <= 480 ? img.height : 480;

    var hRatio = contxt.canvas.width / img.width;
    var vRatio = contxt.canvas.height / img.height;
    var ratio = Math.min(hRatio, vRatio);

    //Draw the image on the display canvas
    contxt.clearRect(0, 0, contxt.canvas.width, contxt.canvas.height);

    contxt.scale(ratio, ratio);
    contxt.drawImage(image, 0, 0);

    //alert("ready to draw features");

    contxt.strokeStyle = "#FFFFFF";
    for (var id in featurePoints) {
      contxt.beginPath();
      contxt.arc(featurePoints[id].x,
        featurePoints[id].y, 2, 0, 2 * Math.PI);
      contxt.stroke();
    }

    //alert("done drawing features");


  }

}



    //]]>

</script>

  <script>
    // tell the embed parent frame the height of the content
    if (window.parent && window.parent.parent){
      window.parent.parent.postMessage(["resultsFrame", {
        height: document.body.getBoundingClientRect().height,
        slug: "h6p64vwg"
      }], "*")
    }
  </script>
</body>
</html>
